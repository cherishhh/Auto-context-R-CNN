{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from modeling.ctx_outs import autoctx_outputs\n",
    "from model.roi_pooling.functions.roi_pool import RoIPoolFunction\n",
    "from model.roi_crop.functions.roi_crop import RoICropFunction\n",
    "from modeling.roi_xform.roi_align.functions.roi_align import RoIAlignFunction\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# The spatial scale should be a list with each level's sc if FPN is applied.\n",
    "def roi_feature_transform(self, blobs_in, rpn_ret, blob_rois='rois', method='RoIPoolF',\n",
    "                              resolution=7, spatial_scale=1. / 16., sampling_ratio=0):\n",
    "        \"\"\"Add the specified RoI pooling method. The sampling_ratio argument\n",
    "        is supported for some, but not all, RoI transform methods.\n",
    "\n",
    "        RoIFeatureTransform abstracts away:\n",
    "          - Use of FPN or not\n",
    "          - Specifics of the transform method\n",
    "        \"\"\"\n",
    "    assert method in {'RoIPoolF', 'RoICrop', 'RoIAlign'}, \\\n",
    "            'Unknown pooling method: {}'.format(method)\n",
    "\n",
    "    # The list suggests the feature maps(blobs_in) from different levels\n",
    "    if isinstance(blobs_in, list):\n",
    "        # FPN case: add RoIFeatureTransform to each FPN level\n",
    "        device_id = blobs_in[0].get_device()\n",
    "        k_max = cfg.FPN.ROI_MAX_LEVEL  # coarsest level of pyramid\n",
    "        k_min = cfg.FPN.ROI_MIN_LEVEL  # finest level of pyramid\n",
    "        assert len(blobs_in) == k_max - k_min + 1\n",
    "        # set a list for appending\n",
    "        bl_out_list = []\n",
    "        for lvl in range(k_min, k_max + 1):\n",
    "            bl_in = blobs_in[k_max - lvl]  # blobs_in is in reversed order\n",
    "            dim_in = blobs_in.size(1)\n",
    "            sc = spatial_scale[k_max - lvl]  # in reversed order\n",
    "            # set up ctx_rois instance in current level\n",
    "            ctx_rois = autoctx_outputs(dim_in,sc)\n",
    "            # each level's rois keys\n",
    "            bl_rois = blob_rois + '_fpn' + str(lvl)\n",
    "# ------------------------------------------------------------------------------- #\n",
    "            if len(rpn_ret[bl_rois]):\n",
    "                # the rois from single level,2D Variable with shape\n",
    "                # (roi_num,5)\n",
    "                rois = Variable(torch.from_numpy(rpn_ret[bl_rois])).cuda(device_id)\n",
    "                \n",
    "                for object_roi in rois:\n",
    "                    # the ctx_roi should be ndarray with shape of (9*5)\n",
    "                    # transform into tensor\n",
    "                    autoctx_rois = torch.from_numpy(ctx_rois(bl_in,object_roi))\n",
    "                    if method == 'RoIPoolF':\n",
    "                        # Warning!: Not check if implementation matches Detectron\n",
    "                        xform_out = RoIPoolFunction(resolution, resolution, sc)(bl_in, autoctx_rois)\n",
    "                    elif method == 'RoICrop':\n",
    "                        # Warning!: Not check if implementation matches Detectron\n",
    "                        grid_xy = net_utils.affine_grid_gen(\n",
    "                            rois, bl_in.size()[2:], self.grid_size)\n",
    "                        grid_yx = torch.stack(\n",
    "                            [grid_xy.data[:, :, :, 1], grid_xy.data[:, :, :, 0]], 3).contiguous()\n",
    "                        xform_out = RoICropFunction()(bl_in, Variable(grid_yx).detach())\n",
    "                        if cfg.CROP_RESIZE_WITH_MAX_POOL:\n",
    "                            xform_out = F.max_pool2d(xform_out, 2, 2)\n",
    "                    elif method == 'RoIAlign':\n",
    "                        xform_out = RoIAlignFunction(\n",
    "                            resolution, resolution, sc, sampling_ratio)(bl_in, autoctx_rois)\n",
    "                    \n",
    "                    # concatenate through dim 1,with the shape of (1,C*9,h,w)\n",
    "                    xform_out = xform_out.view(1,xform_out.size(0)*xform_out.size(1),\n",
    "                                               xform_out.size(2),xform_out.size(3))\n",
    "                    compress_inchannel = xform_out.size(1)\n",
    "                    compress_outchannel = compress_inchannel / 9\n",
    "                    # compress the xform into the original dimension\n",
    "                    compress_conv = nn.Conv2d(compress_inchannel,compress_outchannel,1,1,0)\n",
    "                    compressed_feature = compress_conv(xform_out)\n",
    "                    bl_out_list.append(xform_out)\n",
    "                # to keep the same dimension,cat the xform_outs from single level\n",
    "                bl_out_list = torch.cat(bl_out_list,dim=0)\n",
    "        # The pooled features from all levels are concatenated along the\n",
    "        # batch dimension into a single 4D tensor. \n",
    "        # The shape will be (roi_nums,C,H,W)\n",
    "        xform_shuffled = torch.cat(bl_out_list,dim=0)\n",
    "\n",
    "        # Unshuffle to match rois from dataloader\n",
    "        device_id = xform_shuffled.get_device()\n",
    "        restore_bl = rpn_ret[blob_rois + '_idx_restore_int32']\n",
    "        restore_bl = Variable(\n",
    "                    torch.from_numpy(restore_bl.astype('int64', copy=False))).cuda(device_id)\n",
    "        xform_out = xform_shuffled[restore_bl]\n",
    "    else:\n",
    "        # Single feature level\n",
    "        # rois: holds R regions of interest, each is a 5-tuple\n",
    "        # (batch_idx, x1, y1, x2, y2) specifying an image batch index and a\n",
    "        # rectangle (x1, y1, x2, y2)\n",
    "        device_id = blobs_in.get_device()\n",
    "        rois = Variable(torch.from_numpy(rpn_ret[blob_rois])).cuda(device_id)\n",
    "        if method == 'RoIPoolF':\n",
    "            # spatial_scale[0] is the coarest level for single feature map\n",
    "            xform_out = RoIPoolFunction(resolution, resolution, spatial_scale[0])(blobs_in, rois)\n",
    "        elif method == 'RoICrop':\n",
    "            grid_xy = net_utils.affine_grid_gen(rois, blobs_in.size()[2:], self.grid_size)\n",
    "            grid_yx = torch.stack(\n",
    "                [grid_xy.data[:, :, :, 1], grid_xy.data[:, :, :, 0]], 3).contiguous()\n",
    "            xform_out = RoICropFunction()(blobs_in, Variable(grid_yx).detach())\n",
    "            if cfg.CROP_RESIZE_WITH_MAX_POOL:\n",
    "                xform_out = F.max_pool2d(xform_out, 2, 2)\n",
    "        elif method == 'RoIAlign':\n",
    "            xform_out = RoIAlignFunction(\n",
    "                resolution, resolution, spatial_scale[0], sampling_ratio)(blobs_in, rois)\n",
    "\n",
    "    return xform_out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
